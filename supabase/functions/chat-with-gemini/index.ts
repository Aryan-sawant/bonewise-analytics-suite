
// deno-lint-ignore-file no-explicit-any
import { serve } from "https://deno.land/std@0.168.0/http/server.ts"

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders })
  }

  try {
    // Parse the request body
    const { message, context, userType, userId, analysisId } = await req.json()

    if (!message) {
      return new Response(
        JSON.stringify({ error: 'No message provided' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      )
    }

    // Initialize Gemini API
    const apiKey = Deno.env.get('GEMINI_API_KEY')
    if (!apiKey) {
      return new Response(
        JSON.stringify({ error: 'API key not configured' }),
        { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      )
    }

    console.log(`Processing chat message with Gemini...`)

    // Try to use the specified model first
    const baseURL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-01-21:generateContent"
    const url = `${baseURL}?key=${apiKey}`

    // Prepare the message context
    const userPrompt = message
    const systemContext = context || "You are a professional bone health assistant. Be concise, accurate, and professional in your responses."

    // Prepare the request payload
    const payload = {
      contents: [
        {
          parts: [
            { text: systemContext + "\n\nUser message: " + userPrompt }
          ]
        }
      ],
      generationConfig: {
        temperature: 0.2,
        maxOutputTokens: 800,
      }
    }

    console.log("Sending request to Gemini 2.0 Flash Thinking")
    
    // Call the Gemini API
    const response = await fetch(url, {
      method: "POST",
      headers: {
        "Content-Type": "application/json"
      },
      body: JSON.stringify(payload)
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error("Gemini API error:", errorText)
      
      // Try fallback model
      console.log("Trying fallback to gemini-pro model")
      const fallbackURL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent"
      const fallbackUrl = `${fallbackURL}?key=${apiKey}`
      
      const fallbackResponse = await fetch(fallbackUrl, {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify(payload)
      })
      
      if (!fallbackResponse.ok) {
        const fallbackErrorText = await fallbackResponse.text()
        console.error("Fallback Gemini API error:", fallbackErrorText)
        throw new Error(`Gemini API error: All models failed`)
      }
      
      const fallbackData = await fallbackResponse.json()
      
      if (!fallbackData.candidates || fallbackData.candidates.length === 0) {
        throw new Error("No response generated by the fallback model")
      }
      
      // Extract the response text
      const responseText = fallbackData.candidates[0].content.parts[0].text
      
      // Return the response
      return new Response(
        JSON.stringify({ 
          response: responseText,
          modelUsed: "gemini-pro (fallback)"
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      )
    }

    const data = await response.json()
    console.log("Response received:", JSON.stringify(data))
    
    if (!data.candidates || data.candidates.length === 0 || !data.candidates[0].content || !data.candidates[0].content.parts || data.candidates[0].content.parts.length === 0) {
      // Try fallback model
      console.log("No content from primary model, trying fallback to gemini-pro model")
      const fallbackURL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent"
      const fallbackUrl = `${fallbackURL}?key=${apiKey}`
      
      const fallbackResponse = await fetch(fallbackUrl, {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify(payload)
      })
      
      if (!fallbackResponse.ok) {
        const fallbackErrorText = await fallbackResponse.text()
        console.error("Fallback Gemini API error:", fallbackErrorText)
        throw new Error(`Gemini API error: All models failed`)
      }
      
      const fallbackData = await fallbackResponse.json()
      
      if (!fallbackData.candidates || fallbackData.candidates.length === 0) {
        throw new Error("No response generated by the fallback model")
      }
      
      // Extract the response text
      const responseText = fallbackData.candidates[0].content.parts[0].text
      
      // Return the response
      return new Response(
        JSON.stringify({ 
          response: responseText,
          modelUsed: "gemini-pro (fallback)"
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      )
    }

    // Extract the response text
    const responseText = data.candidates[0].content.parts[0].text

    // Return the response
    return new Response(
      JSON.stringify({ 
        response: responseText,
        modelUsed: "gemini-2.0-flash-thinking-exp-01-21" 
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )

  } catch (error) {
    console.error("Error processing chat:", error)
    return new Response(
      JSON.stringify({ error: `Failed to process the message: ${error.message}` }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )
  }
})
